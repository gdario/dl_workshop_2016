* Deep Learning for Pharma and Agri-Food workshop

** Pierre Baldi 

*** Intro
- ML starts with Gauss. Today we try to do something similar, but with highly non-linear functions and in much higher dimensional spaces.
- Older approaches. Rosenblatt, Fukushima and [[https://en.wikibooks.org/wiki/Artificial_Neural_Networks/Hebbian_Learning][Hebbian Learning]].
- Computer vision: error rate from 30% to 4.9% (superhuman performance)

*** TODO DL
- First experiments, 1 layer
- 1.5 layers (is this correct?!?). Apparently equivalent to [[https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma][Johnson-Lindenstrauss Lemma]] and random projections.
- 2 layers: autoencoders, where the network tries to recreate the input without just learning to copy it. If the functions are linear, the problem is convex and we obtain the PCA. If the functions are non-linear (as it usually is), the problem is non convex, and we obtain non linear manifolds.
- Note: non-convexity does not imply a large number of local minima. Mostly we have saddle points. Intuitively, this happens because it is highly unlikely to have a local minumum for all the dimensions in a highly dimensional space.
- Back-propagation is not the only way to learn the parameters of a network, but there is no need to look elsewhere, since it is actually optimal, in the sense that it takes the smallest number of operations. This applies to MLP and to RNNs as well.

*** More into DL
Two types of architectures.
- CNNs, where inputs have the same size.
- RNNs(? I haven't recorded it), where inputs have different sizes. Examples include DNA, proteins etc

*** TODO Inner and outer approaches for RNNs 
- Inner :: The input graph must be acyclic. The inner approach "crawls" along the edges
- Outer :: The RNN is perpendicular to the data (is this the typical network where you have an unfolded graph? It looked like the first example was actually such a thing)

*** Applications
Three main areas of application: 1) Biology, 2) Chemistry, 3) Physics.

**** Biology
Prediction of protein secondary and tertiary structures. Here the challenge is to predict the amino-acids that are far apart on the linear sequence, but close to each other in the folded 3D structure. An important concept here is a [[https://en.wikipedia.org/wiki/Protein_contact_map][Contact Map]] which represents the distance between all possible amino acid residue pairs of a three-dimensional protein structure using a binary two-dimensional matrix. If one can predict accurately a contact map, then he or she can accurately predict the 3D structure. In 1999 they published a paper, [[http://www.ncbi.nlm.nih.gov/pubmed/10743560][Baldi, Pollastri 1999]] where the prediction accuracy was 78%. In 2014 they published another paper [[http://www.ncbi.nlm.nih.gov/pubmed/24860169][Magnan, Baldi 2014]], where the accuracy is 95% and they claim that the problem is solved. Baldi says that one cannot get 100% due to the errors in the databases and the lack of chaperones.
They also applied a method for the prediction of contact maps. Here they have a sliding window that is moving in four directions. He cited two papers on this: [[http://www.jmlr.org/papers/volume4/baldi03a/baldi03a.pdf][Baldi, Pollastri 2003]] and, more recently, [[http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3463120/][Di Lena, Nagata, Baldi 2012]]. Here the accuracy is much lower, 20-30%. These methods were used for the Critical Assessment of Techniques for Protein Structure Prediction ([[http://predictioncenter.org][CASP)]] competition.

**** Chemistry
We have many representations of small molecules properties, for example Smiles, fingerprints etc. Fingerprints are typically fixed vectors of 1e04-1e05 features, and they are very sparse. One may want to find compressed representations of these features, for example using autoencoders. If you have data of variable size, then you must use RNNs. The challenge is that there is no canonical orientation for a molecule, and one may want to take all the possible orientations. This is what is done in [[http://www.ncbi.nlm.nih.gov/pubmed/23795551][Lusci, Pollastri, Baldi 2013]] where they predict the aqueous solubility of drug-like molecules. In this work they use the *inner approach*, while [[https://papers.nips.cc/paper/5954-convolutional-networks-on-graphs-for-learning-molecular-fingerprints.pdf][Duvenaud et al 2015]] use the outer approach.

One final example he showed was the *prediction of chemical reactions*. In [[http://www.ncbi.nlm.nih.gov/pubmed/19719121][Chen, Baldi 2009]] they develop a rule-based approach. They went on training a *siamese architecture*, as described in [[http://pubs.acs.org/doi/abs/10.1021/ci200207y][Kayala, Azencott 2011]].


** Hugo Ceulemans (Janssen)

*** CAPE: Compound Activity Prediction Effort
- Resources :: CHEMBL, OpenTox, ABCD, GSSTAR, Thomson-Reuters
- Various feature sets: 2D and 3D fingerprints. Biological assays. In particular they have a collaboration with a company called [[http://genometry.com][Genometry]] specialized in L1000. A brief description of the technology can be found [[http://genometry.com/#technology][here]].

*** TODO add something about the technology and the company

**** Rationale
1. Select compounds for screens.
2. Annotate hit series to (de) prioritize compounds.
3. Hypotheses generation about the compounds.

They have single label vs. multi-label and single assay vs. multi-assay problems, but the idea is to do something similar to what Google did in the [[http://arxiv.org/pdf/1502.02072.pdf][Massively Multi-Task Nets paper]] and as briefly described on [[http://googleresearch.blogspot.ch/2015/03/large-scale-machine-learning-for-drug.html][Google Blog]].
They use [[http://arxiv.org/abs/1509.04610][MACAU]], a Scalable Bayesian Multi-relational Factorization with Side Information using MCMC.

More in general, Jenssen has a collaboration with Sepp Hochreiter and Yives Moreau, who are acting as consultants on a couple of projects. Ceulemans referred to the papers (from Hochreiter's grop) on [[http://www.bioinf.jku.at/publications/2014/NIPS2014a.pdf][Virtual Screenings]] and toxicity prediction like in [[http://journal.frontiersin.org/article/10.3389/fenvs.2015.00080/full][Mayr et al 2016]] and [[http://arxiv.org/pdf/1503.01445v1.pdf][Unterthiner et al 2015]].

Something that is currently ongoing: they have historic data on translocation of a nuclear receptor, 6 images for each of 500K compounds (15 TB of data), 3 channels. They used [[http://cellprofiler.org][Cell Profiler]] from the Broad Institute to perform cell segmentation and they extract 841 morphological features.
Combining the imaging screen, segmentation, MACAU they obtain 30 virtual screens.

*Quite a bit of information missing here. I did not get many of the details. If someone had got something more in his notes, this would be great*

** Djork-Arne' Clevert - Decoding Biological Data with Rectified Factor Networks (RFN)

He's an ex student of Sepp Hochreiter's. RFNs are work done mostly when he was at the Johannes Kepler University in Linz. Among other topics, he mentioned a modified version of the rectified linear units (ReLUs) that can speed up learning in deep neural networks (DNNs). These are the [[http://arxiv.org/abs/1511.07289][Exponential Linear Units.]] However the main topic of the talk were the Rectified Factor Networks (resources can be found in [[http://arxiv.org/abs/1502.06464][Clevert 2015]], [[http://arxiv.org/abs/1502.06464][Clevert (NIPS)]], and in [[http://www.bioinf.jku.at/publications/2014/NIPS2014b.pdf][RFNs and Dropout]]). The code can be downloaded from [[https://github.com/untom/librfn][GitHub]], and it compiles on a MacBook Pro (Yosemite) with CUDA installed. I had issues on El Capitan, but it should be reasonably easy to fix.

RFNs are somewhat like an autoencoder, in the sense that they try to reconstruct the input they receive, without learning just to copy it to the output. Therefore, an autoencoder is forced to learn a representation that contains the essential features of the input, discarding the inessential ones. The main goals of the RFN (as stated in the papers) is to "Our goal is to construct representations of the input that (1) are sparse, (2) are non-negative, (3) are non-linear, (4) use many code units, and (5) model structures in the input". The non-negativity here is along the lines of what is done in [[https://en.wikipedia.org/wiki/Non-negative_matrix_factorization][Non-Negative Matrix Factorization.]]

Clevert generated a synthetic dataset of 100 samples and 100 features and injected biclusters in it (details?), and tested a number of unsupervised methods measuring 1) sparseness, 2) reconstruction error and 3) model covariance (not sure I understand what is meant here).

PUT THE CONCLUSION OF THIS ANALYSIS HERE

*** Pre-training DNNs with RFNs
They used RFN as a pre-training for deep neural networks. They compare the performance of a DNN pre-trained with an RFN with an SVM and with DNNs pre-trained with other methods, including Restricted Boltzmann Machines (RBM), Stacked Auto-Encoders (SAE), Stacked Denoising Auto-Encoders (SDAE), Deep Belief Networks (DBN). In almost all cases (they test on multiple data-sets), the DNN pre-trained with the RNF outperforms the other methods.

*** Applications to Drug Discovery
One of the main goals of this method is to produce a sparse representation of a data-set that still effectively allows to identify rare events. 

*** Deep Learning @ Bayer
They use DL and RFNs for large HCS, CNNs are used on histopath. images. Prediction of bioactivity using molecular fingerprints, off-target prediction and other things.

**** Gene Expression Landscape (work done with or by Helge Roider)
The have 40.000 microarrays, all Affymetrix, and they have done a hierarchical annotation, categorizing the arrays into 12 classes (tissue types, if I understand correctly). Within each category there are sub-category that can refer to pathologies or more specific annotations. All the data have been summarized with [[https://www.bioconductor.org/packages/3.3/bioc/vignettes/farms/inst/doc/farms.pdf][FARMS]], a Bioconductor package developed by Clevert and based on Factor Analysis. They removed the non-informative genes (~10%) and ran RFN with 50(? in the paper they say 500) hidden units, 30% "salt and pepper noise" and 5% dropout. They obtain a representation that is then plotted using t-SNE and they see some separation across the 12 classes.

**** Decoding Copy Number Variants
They have a set of 400 Affymetrix chips (SNP arrays or copy number, or hybrid, I don't know). The data set is smaller, but they apply something similar to what they did in the previous case. In my notes I cannot find anything else, so I guess he did not show any results beyond a couple of t-SNE plots.


** Gerard Van Westen: Target Prediction, QSAR, PCM

He was a a PostDoc at the EBI, where he worked on simulation-based bioactivity modeling using GPUs (and actually building the first instances at the EBI).

He is working now on the prediction of compound-protein interactions, trying to explain the polypharmacologycal effects. His starting point is ChEMBL, which contains 14 million data points. However, if one is interested only in high-quality data points, you can only use 3% of the data set, i.e. 400,000 data points.

*** In Silico Target Fishing
It is typical to choose a threshold of 10uM to call something active. According to this criterion, 90% of the high quality data points are active. They put the threshold to 300nM, and this now changes the balance of active/inactive into something closer to 50% (not exactly, but not too far, and I don't have the precise numbers). They extract the circular fingerprints and some other physical properties for the molecules, while for the proteins they divide them into 20 equal parts (uh?)

They compare Naive Bayes (NB), Random Forest binary class QSAR (BC_QSAR), Random Forest multi class QSAR (MC-QSAR), Multi Class Deep Neural Nets (MC-DNN) and Proteochemometric Deep Neural Networks (PCM-DNN) using both open source reources (RDKIT, Theano, Lasagne, Scikit-Learn) and commercial software (Pipeline Pilot + R) on a standardized high quality ChEMBL subset that is available for download (WHERE?). All methods are validated using [[https://en.wikipedia.org/wiki/Matthews_correlation_coefficient][Matthews Correlation Coefficient]]. They use two partitioning schemes for validation: random partitioning and partitioning by year (training=pre 2013 and validation from 2013 on). The rationale being that this can be a more realistic representation of what happens in prospective virtual screenings. ChEMBL contains compound series, and this suggests that taking advantage of the prospective nature of the studies can be more realistic and remove some biases.

When using the random partitioning, the best performing method is MC-DNN (MCC=0.66), with the PCM-DNN immediately close (MCC=0.64). When they use the "year split" (as they call it) the performance deteriorates significantly. In the Sheffield abstact the best MCC is about .4 but the numbers Gerard showed were more around MCC~0.2.

*** Observations
Overall he had 63 models, and he noted that averaging multiple models produces the best performance. Apparently he just used plain multi-layered perceptrons, and he is planning now to use RBMs, CNNs and RNNs. Hochreiter said that he would *not* accept this work for publication because he is convinced that there are still serious biases. In particular he pointed out that Gerard should first cluster the compounds (and what about the proteins? I haven't written anything about this) and select representatives removing compounds that are too similar to each other, as this would make the results look better than they would actually be.


** Sepp Hochreiter, Johannes Kepler Universitaet

He gave an introduction to the main challenge associated with deep neural networks, i.e. the vanishing/exploding gradient problem. The other problem, not unrelated, is volume deformation. The result is that you end up storing all you information in one single neuron, and/or one neuron decides for all the others.
If one can keep the determinant of the Jacobian matrix around 1, things are OK, since this correspond to a transformation that conserves the volume between the original and the transformed space, and doesn't lead to vanishing or exploding gradients. Some solutions to these problems, from an historical perspective, have been:
1. Pre-training (Hinton 2006), for example with Denoising Autoencoders or Restricted Boltzmann Machines
2. Rectified Linear Units: the have a derivative of 1, which means that the gradient is in the right region, especially if weights are properly initialized. They have essentially replaced pre-training.
3. LSTM: this works on recurrent neural networks, and has been introduced by Hochreiter and Schmidhuber
4. A new one is [[https://arxiv.org/abs/1505.00387][Highway Networks]] which finds clever ways to let information circulate through the network. Another one are Residual Networks (resource can be found in [[http://arxiv.org/abs/1512.03385][He et al 2015]], [[http://arxiv.org/abs/1603.05027][He et al 2016]], on [[https://github.com/KaimingHe/resnet-1k-layers][GitHub]], on [[http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf][Microsoft Research]]. Here they have architectures with 150 and even 1000 layers. At the moment, ResNet is the state of the art for image recognition.

The general principle therefore is to compute an output like $\mathbf{y} = \mathbf{x} + F(\mathbf{x})$, where the Jacobian would then be $\frac{\partial{\mathbf{y}}}{\partial \mathbf{x}} = \mathbf{I} + \frac{\partial F(\mathbf{x})}{\partial \mathbf{x}}$

Minibatch learning has a self-regularizing effect. You always have different errors, but to make things work, you need *a lot* of data.

*** DL for Drug Design
Are there enough data? Not clear. Hochreiter says that pharma companies should find a way to put together their data (Ceulemans said something in this direction). One of the main problems is that the inactive compounds are usually not part of the datasets, or not enough, and this is a big limitation.

*** Target Deconvolution
You have drugs, target phenotypes, you observe the phenotype and you want to know what the target was. They use CNNs on HCSs for this. You can look at [[http://user2015.math.aau.dk/presentations/92.pdf][Ceuleman's slides]].

*** Toxicity Prediction
    Hochreiter's group participated in the [[https://tripod.nih.gov/tox21/challenge/][Tox21 Challenge 2014]] and won the large majority of the challenges. The most significant papers of the Hochreiter's group in chemoinformatics are [[http://www.bioinf.jku.at/publications/2014/NIPS2014a.pdf][Unterthiner et al. 2014]], [[http://arxiv.org/abs/1503.01445][Unterthiner et al. 2015]], [[http://journal.frontiersin.org/article/10.3389/fenvs.2015.00080/full][Mayr et al. 2016]]. One of the main ideas is [[https://en.wikipedia.org/wiki/Multi-task_learning][Multi-task Learning]], where different networks receive different types of inputs, for example if different assays have been performed on the same compound, and aggregate these networks in one or more common hidden layer that learns more abstract and general representations of the data.

One point where I am somewhat confused is the fact that, on one hand, Hochreither re-stated the necessity to cluster the compounds and found a representative for very similar structures. On the other hand, he referred to the problem due to *activity cliffs*, where two compounds, or groups of compounds, can have very similar structure and still show large differences in potency. It is not clear to me whether Hochreiter was referring to supervised clustering or not.

*** Image analysis
They have applied DL on a number of HCS. One of the challenges is the large number of images that one need to annotate. Astra Zeneca used the [[https://www.mturk.com/mturk/welcome][Amazon Mechanical Turk]] to annotate (what? Images or patents? I can't remember, but the idea is similar). Hochreiter said they do not image segmentation, but rather they submit the whole image to the network. 


** Oliver Stegle: Deep Learning in Regulatory Genomics
The ML part of this work was performed by Christof Angermueller, who is (was) a student of Gharhamani. The main topic of the talk is the analysis of the data described in [[https://cangermueller.com/wp-content/papercite-data/pdf/angermueller_parallel_2016.pdf][Angermueller et al. 2016]]. In this work they profile 61 mouse embryonic stem cells both from the transcriptional and epigentic point of view. They produce methylomes and transcriptomes from the same cells, but the amount of material is very low, and this implies a lot of zeros in the expression count matrix, and a lot of NAs in the methylome matrix (I guess in both cases they should be considered as missing values, as the zeroes in the expression count matrix are presumably PCR dropouts). Thera are models for the imputations of the methylation status, but they tend to be slow or inefficient. Here they develop a multi-task network that makes use of both the transcriptome and the methylome.

More precisely, they develop a multi=task deep neural network to jointly predict the mehtylation of multiple cells from more than 10000 genomic, epigenomic and physiochemical features. The network infers bot shared and cell-specific latent features and uses a novel dropout approach. Therefore they have one CNN for the transcriptome and one for the methylome and then they have one or more fully connected layers above. The larger the "windows" (I guess the convolutional kernels) the better the AUC, suggesting that the broader context is taken into account, the better. The method is called DeepCpG, but I could not find anything yet.

They are also building up a similar system that tries to predict (but I'm not sure I have recorded this correctly), methylation level and methylation variance/variablilty. This is somehow connected to the identification of motifs that are predictive of cell heterogenieity. The motifs are from the first hidden layer, and Stegle compares them with an "edge detector" in a CNN for image classification. 

** Other things
- [[http://homes.cs.washington.edu/~pedrod/papers/nips14.pdf][Deep Symmetry Networks]]
- Ceulemans' project for data sharing. Uwe has better notes on this.
